{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\veasn\\OneDrive - TUX Global Institute\\AI001 Module 2 - Assignment 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import geopandas as gpd\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "from geopy.distance import geodesic as GD\n",
    "from shutil import move\n",
    "\n",
    "levels = ['province','district','commune']\n",
    "\n",
    "this_path = os.getcwd()\n",
    "print(this_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = pd.read_json('Map/data_with_neighbors.json',dtype={\"Geocode\":str})\n",
    "dft1 = pd.read_csv('Map/data.csv',dtype={\"Geocode\":str})\n",
    "print('Shape1:',df1.shape)\n",
    "print('Shape2:',dft1.shape)\n",
    "csvdata = []\n",
    "for i, row in df1.iterrows():\n",
    "    neighbors = row['neighbors']\n",
    "    for neighbor in neighbors:\n",
    "        csvdata.append({\n",
    "            'Order': row['Order'],\n",
    "            'Geocode': row['Geocode'],\n",
    "            'Name': row['Name'],\n",
    "            'Neighbor Name': neighbor,\n",
    "            # 'Neighbor Code': '',\n",
    "        })\n",
    "    # if len(neighbors) == 0:\n",
    "    #     print(\"%5d  %6s  %s\" % (row['Order'],row['Geocode'],row['Name']))\n",
    "df3 = pd.DataFrame(csvdata)\n",
    "print('Shape3:',df3.shape)\n",
    "print('Geocode:',df3['Geocode'].nunique())\n",
    "print('Missing:',df1['Geocode'].nunique() - df3['Geocode'].nunique())\n",
    "\n",
    "\n",
    "gp = dft1.groupby('Name',as_index=False)\\\n",
    "    .agg({'Geocode':'first','Order':'count'})\\\n",
    "    .rename(columns={'Order':'Count'})\\\n",
    "    .sort_values('Count',ascending=False)\\\n",
    "    .query('Count==1')\n",
    "print('Group :',gp.shape)\n",
    "print('Name  :',gp['Name'].nunique())\n",
    "gp.to_csv('test.csv',index=False)\n",
    "gp = gp[['Geocode','Name']].rename(columns={'Geocode':'Neighbor Code','Name':'Neighbor Name'})\n",
    "df3 = pd.merge(df3, gp, how='left', on='Neighbor Name')\n",
    "\n",
    "# for i,row in df3.iterrows():\n",
    "#     print(i)\n",
    "#     for _, row2 in gp.iterrows():\n",
    "#         if row['Neighbor Name'] == row2['Name']:\n",
    "#             df3.at[i,'Neighbor Code'] = row2['Geocode']\n",
    "#             break\n",
    "\n",
    "print('Shape3:',df3.shape)\n",
    "print('Null  :',df3['Neighbor Code'].isnull().sum())\n",
    "df3.to_csv('Map/communes_neighbors.csv',index=False)\n",
    "df3[df3['Neighbor Code'].isna()].to_csv('test_null.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# communes.json\n",
      "shape   : (1633, 11)\n",
      "columns : ['id', 'objectid', 'level', 'hrname', 'hrpcode', 'hrparent', 'com_name', 'com_code', 'dis_code', 'pro_code', 'geometry']\n",
      "hrpcode : 1633\n",
      "hrparent: 197\n",
      "\n",
      "# data.json\n",
      "rows: 1652\n",
      "Not Found: 98\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gdf = gpd.read_file('Map/communes.json', encoding='utf-8')\n",
    "print('\\n# communes.json')\n",
    "print('shape   :',gdf.shape)\n",
    "print('columns :',gdf.columns.to_list())\n",
    "print('hrpcode :',gdf['hrpcode'].nunique())\n",
    "print('hrparent:',gdf['hrparent'].nunique())\n",
    "# print(gdf.loc[0,:])\n",
    "# print(gdf.info())\n",
    "\n",
    "print('\\n# data.json')\n",
    "data = json.load(open('Map/data.json', mode='r', encoding='utf-8'))\n",
    "print('rows:',len(data))\n",
    "missing_communes = []\n",
    "for i,row in enumerate(data):\n",
    "    commune_name = row['Name']\n",
    "    commune_code = row['Geocode']\n",
    "    target_commune = gdf[gdf['com_code'] == commune_code]\n",
    "    data[i]['Neighbors'] = []\n",
    "    if target_commune.empty:\n",
    "        missing_communes.append({\n",
    "            'Geocode': row['Geocode'],\n",
    "            'Name': row['Name'],\n",
    "        })\n",
    "    else:\n",
    "        neighbors = gdf[gdf.geometry.touches(target_commune.geometry.iloc[0])]\n",
    "        data[i]['Neighbors'] = neighbors['com_code'].to_list()\n",
    "print('Not Found:',len(missing_communes))\n",
    "with open('Map/test_neighbor.json', 'w', encoding='utf-8') as fw:\n",
    "    json.dump(data, fw, ensure_ascii=False, indent=4)\n",
    "pd.DataFrame(missing_communes).to_csv('Map/test_missing.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gazetteer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape1: (1652, 8)\n",
      "Shape2: (1652, 10)\n",
      "Shape3: (1652, 9)\n",
      "Geocode2: 1652\n",
      "Geocode3: 1652\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fileR = 'Gazetteer/gazetteer.csv'\n",
    "df1 = pd.read_csv(fileR)\n",
    "dft1 = pd.read_csv('Map/data.csv',dtype={\"Geocode\":str})\n",
    "df3 = pd.read_json('Map/data.json',dtype={\"Geocode\":str})\n",
    "df1 = df1.query('Level==3')\n",
    "dft1['Code'] = dft1['Geocode'].apply(lambda x: f'KH{x}' if len(x) % 2 == 0 else f'KH0{x}')\n",
    "print('Shape1:',df1.shape)\n",
    "print('Shape2:',dft1.shape)\n",
    "print('Shape3:',df3.shape)\n",
    "print('Geocode2:',dft1['Geocode'].nunique())\n",
    "print('Geocode3:',df3['Geocode'].nunique())\n",
    "# set1 = set(df1['Code'].unique())\n",
    "# set2 = set(df2['Code'].unique())\n",
    "# print('set1:',set1.difference(set2))\n",
    "# print('set2:',set2.difference(set1))\n",
    "# df2 = pd.merge(df2, df3[['Geocode','Latitude','Longitude']], how='left', on='Geocode')\n",
    "# del df2['Code']\n",
    "# df2.to_csv('data.csv',index=False)\n",
    "# gp = df2.groupby('Name',as_index=False)\\\n",
    "#     .agg({'Order':'count'})\\\n",
    "#     .rename(columns={'Order':'Count'})\\\n",
    "#     .sort_values('Count',ascending=False)\\\n",
    "#     .query('Count>1')\n",
    "# print(gp.shape)\n",
    "# gp.to_csv('test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1632, 8)\n",
      "Json : 1632\n",
      "Shape2: (4710, 8)\n",
      "codes : 9420\n",
      "\n",
      "# Results\n",
      "Shape X1: (1632, 2)\n",
      "Shape X2: (1632, 2)\n",
      "Shape X3: (1632, 12)\n",
      "equal\n",
      "1    1500\n",
      "0     132\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('data/Map/geonode.csv').query('level==3')\n",
    "columns = df.columns\n",
    "print('Shape:',df.shape)\n",
    "data = json.load(open('data/Map/graph.json', mode='r', encoding='utf-8'))\n",
    "print('Json :',len(data))\n",
    "\n",
    "\n",
    "fileR = 'data/Map/geonode/commune.json'\n",
    "fileW = 'data/Map/test.json'\n",
    "with open(fileR, mode='r', encoding='utf-8') as fr,\\\n",
    "    open(fileW, mode='w', encoding='utf-8') as fw:\n",
    "    data = json.load(fr)\n",
    "    print('Json :',len(data['features']))\n",
    "    print(data['features'][0]['properties'].keys())\n",
    "    properties = []\n",
    "    for i,row in enumerate(data['features']):\n",
    "        source_adm = row['properties']['source_adm']\n",
    "        geocode = f'KH{source_adm}' if len(source_adm) % 2 == 0 else f'KH0{source_adm}'\n",
    "        dfx = df[df['code'] == geocode]\n",
    "        if dfx.shape[0] == 1:\n",
    "            data['features'][i]['properties']['adm3_altnm'] = dfx.iloc[0]['name_km']\n",
    "        else:\n",
    "            print('Not Found:', source_adm, geocode, row['properties']['adm3_altnm'])\n",
    "        properties.append(row['properties'])\n",
    "    json.dump(data, fw, separators=(',', ':')) \n",
    "    # json.dump(properties, fw, indent=4)\n",
    "\n",
    "\n",
    "# for i,row in enumerate(data):\n",
    "#     dfx = df[df['code'] == row['code']]\n",
    "#     if dfx.shape[0] == 1:\n",
    "#         data[i]['name_km'] = dfx.iloc[0]['name_km']\n",
    "#     else:\n",
    "#         print('Not Found',i)\n",
    "\n",
    "# with open('data/Map/test.json', mode='w', encoding='utf-8') as fw:\n",
    "#     json.dump(data, fw, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1632, 8)\n",
      "Json : 1632\n",
      "Shape2: (4710, 8)\n",
      "codes : 9420\n",
      "\n",
      "# Results\n",
      "Shape X1: (1632, 3)\n",
      "Shape X2: (1632, 3)\n",
      "Shape X3: (1632, 14)\n",
      "equal\n",
      "1    1495\n",
      "0     137\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('data/Map/geonode.csv').query('level==3')\n",
    "columns = df.columns\n",
    "print('Shape:',df.shape)\n",
    "data = json.load(open('data/Map/graph.json', mode='r', encoding='utf-8'))\n",
    "print('Json :',len(data))\n",
    "\n",
    "for i,row in enumerate(data):\n",
    "    data[i]['count'] = len(row['neighbors'])\n",
    "    data[i]['neighbors'] = set([x['code'] for x in row['neighbors']])\n",
    "# pprint(data[0])\n",
    "\n",
    "df2 = pd.read_csv('data\\Map\\geonode_neighbor.csv').query('level==3')\n",
    "codes1 = df2['code1'].to_list()\n",
    "codes2 = df2['code2'].to_list()\n",
    "codes = codes1 + codes2\n",
    "print('Shape2:',df2.shape)\n",
    "print('codes :',len(codes))\n",
    "\n",
    "def get_neighbors(code):\n",
    "    neighbor_set = {code}\n",
    "    dfx = df2[(df2['code1']==code) | (df2['code2']==code)]\n",
    "    set1 = set(dfx['code1'].to_list())\n",
    "    set2 = set(dfx['code2'].to_list())\n",
    "    neighbor_set = neighbor_set.union(set1)\n",
    "    neighbor_set = neighbor_set.union(set2)\n",
    "    neighbor_set.remove(code) \n",
    "    return neighbor_set\n",
    "\n",
    "df['neighbors'] = df['code'].apply(get_neighbors)\n",
    "# df['neighbors'] = df['code'].apply(lambda x: codes.count(x))\n",
    "# for i,row in df.iterrows():\n",
    "\n",
    "\n",
    "\n",
    "print('\\n# Results')\n",
    "dft1 = pd.DataFrame(data,columns=['code','neighbors'])\n",
    "dft2 = df[['code','neighbors']].copy()\n",
    "dft1['num'] = dft1['neighbors'].apply(lambda x: len(x))\n",
    "dft2['num'] = dft2['neighbors'].apply(lambda x: len(x))\n",
    "dft3 = pd.merge(dft1, dft2, how='left', on='code',suffixes=('_M','_V'))\n",
    "dft3['equal'] = np.where(dft3['neighbors_M']==dft3['neighbors_V'], 1, 0)\n",
    "dft3 = pd.merge(dft3, df, how='left', on='code')\n",
    "print('Shape X1:',dft1.shape)\n",
    "print('Shape X2:',dft2.shape)\n",
    "print('Shape X3:',dft3.shape)\n",
    "print(dft3['equal'].value_counts())\n",
    "dft1.sort_values('code').to_csv('test_1.csv',index=False)\n",
    "dft2.sort_values('code').to_csv('test_2.csv',index=False)\n",
    "dft3.query('equal==0').sort_values('code').to_csv('test_3.csv',index=False,columns=\"code,num_M,num_V,name_en,name_km,neighbors_M,neighbors_V\".split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2\n",
      "1632\n",
      "Shape: (1632, 6)\n",
      "code : 1632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "json_data = json.load(open('data/Map/template.json', mode='r', encoding='utf-8'))\n",
    "data = json.load(open('data/Map/graph.json', mode='r', encoding='utf-8'))\n",
    "print()\n",
    "print(len(data))\n",
    "temp = json_data[\"features\"][0].copy()\n",
    "json_data[\"features\"].clear()\n",
    "csvdata = []\n",
    "for row in data:\n",
    "    # if row['code'] == 'KH010201':\n",
    "    #     for neighbor in row['neighbors']:\n",
    "    #         print(neighbor)\n",
    "    #         obj = temp.copy()\n",
    "    #         obj['properties']['code'] = neighbor['code']\n",
    "    #         obj['properties']['name'] = neighbor['name']\n",
    "    #         obj['geometry']['coordinates'] = [neighbor['lng'],neighbor['lat']]\n",
    "    #         json_data[\"features\"].append(deepcopy(obj))\n",
    "    #     break\n",
    "\n",
    "    csvdata.append({\n",
    "        \"order\": row[\"Order\"],\n",
    "        \"code\": row[\"code\"],\n",
    "        \"name_en\": row[\"name_en\"],\n",
    "        \"name_km\": row[\"name_km\"],\n",
    "        \"longitude\": row[\"Longitude\"],\n",
    "        \"latitude\": row[\"Latitude\"],\n",
    "    })\n",
    "\n",
    "\n",
    "df = pd.DataFrame(csvdata)\n",
    "print('Shape:',df.shape)\n",
    "print('code :',df['code'].nunique())\n",
    "df.to_csv('test.csv',index=False)\n",
    "\n",
    "# with open('data/Map/test.json', mode='w', encoding='utf-8') as fw:\n",
    "#     json.dump(json_data, fw, indent=4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from geopy.distance import geodesic as GD\n",
    "point1 = (row['latitude'] , row['longitude'])\n",
    "point2 = (row['latitude'] , row['longitude'])\n",
    "distance = GD(point1,point2).km\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(this_path, 'data/Map/graph.json')\n",
    "\n",
    "with open(filepath, mode='r', encoding='utf-8') as fr,\\\n",
    "    open('test.json', mode='w', encoding='utf-8') as fw:\n",
    "    data = json.load(fr)\n",
    "    node_lookup = {node['code']: node for node in data}\n",
    "    g_scores = {node['code']: float('inf') for node in data}\n",
    "    json.dump(g_scores, fw, indent=4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1632, 8)\n",
      "Json : 1632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('data/Map/geonode.csv').query('level==3')\n",
    "columns = df.columns\n",
    "print('Shape:',df.shape)\n",
    "data = json.load(open('static\\json\\commune.json', mode='r', encoding='utf-8'))\n",
    "print('Json :',len(data[\"features\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.remove('test.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
